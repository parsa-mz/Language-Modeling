{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "SwLDo41i35P0",
      "metadata": {
        "id": "SwLDo41i35P0"
      },
      "source": [
        "NLP 243 Language Modeling - Parsa Mazaheri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08f4d785",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08f4d785",
        "outputId": "08a139d3-d95f-4a7e-e8f8-02f4a2f3c1d7"
      },
      "outputs": [],
      "source": [
        "# Uncomment if running code on Colab\n",
        "! pip install datasets torchtext\n",
        "! mkdir output "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34573d86",
      "metadata": {
        "id": "34573d86"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchtext.vocab as vocab\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "from tqdm import tqdm\n",
        "from collections import Counter\n",
        "import seaborn as sns\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Y8Y2HWp74DqW",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8Y2HWp74DqW",
        "outputId": "cb1bb642-8c7e-4a67-e12e-8db5fe575a22"
      },
      "outputs": [],
      "source": [
        "# Set device = CUDA if available\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print('Device: ', device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "236a4729",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "b2d86fcf25244ca89735ec259fa0815f",
            "5f3b35b26023438196043a8b10ad45c4",
            "4435356fa71a43a18722c9690ba65baf",
            "f3b078b908ed4f66bad274c034e1c0e2",
            "71e4d85613ef40c68f43f2fd532b9174",
            "95e8fad990ad418c865fefcf4ec0754a",
            "7051e36a3fd4470bb64a86c5f8ee4c3c",
            "8cf24b683f9b42ceb013484313a1adf9",
            "212c13238a284306a460283098722aa4",
            "3d2501ddf98f44e9bbe04a543850e632",
            "a13b454c3a4c49c8bacdf512b57d9d02"
          ]
        },
        "id": "236a4729",
        "outputId": "0ae5a2ae-2af2-4714-df50-429cae2c162b"
      },
      "outputs": [],
      "source": [
        "# Download the dataset using HuggingFace load_dataset\n",
        "dataset = load_dataset('ptb_text_only')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HKf0ZagsWQ97",
      "metadata": {
        "id": "HKf0ZagsWQ97"
      },
      "source": [
        "#### Preprocess and Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "417c978d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "417c978d",
        "outputId": "48fa0085-c9b9-4c4f-d8c7-fc4ac33e15e1"
      },
      "outputs": [],
      "source": [
        "# View Dataset Splits\n",
        "print('Dataset Split:', dataset)\n",
        "\n",
        "# Read data\n",
        "train_data = dataset['train']['sentence']\n",
        "val_data = dataset['validation']['sentence']\n",
        "test_data = dataset['test']['sentence']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ff649d4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ff649d4",
        "outputId": "206ee06d-82ac-4c92-ea80-214b5d53baba"
      },
      "outputs": [],
      "source": [
        "\n",
        "# List of Tokenized Words in the Train Corpus\n",
        "def preprocess(data):\n",
        "    print(\"> Tokenizing the data...\")\n",
        "    tokenized_data = []\n",
        "    for sentence in tqdm(data):\n",
        "        tokenized_data += ['<start>'] + sentence.split()\n",
        "\n",
        "    # List of Unique Words\n",
        "    words_freq = Counter(tokenized_data)\n",
        "    VOCAB_SIZE = len(words_freq)\n",
        "\n",
        "    print()\n",
        "    print(\"> Creating Word2Idx and Idx2Word...\")\n",
        "    word2idx = { word: idx for idx, word in enumerate(words_freq) }\n",
        "    idx2word = { idx: word for word,idx in word2idx.items() }\n",
        "    \n",
        "    print(\"> Done\")\n",
        "    return word2idx, idx2word, VOCAB_SIZE\n",
        "\n",
        "\n",
        "word2idx, idx2word, VOCAB_SIZE = preprocess(train_data)\n",
        "# Print Vocab Length\n",
        "print('\\nVocab Size: ', VOCAB_SIZE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc1f918e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc1f918e",
        "outputId": "d7e68b3b-1749-4113-b9a3-b4877c7218c2"
      },
      "outputs": [],
      "source": [
        "# Load GloVe Embeddings\n",
        "GLOVE_DIM = 300\n",
        "glove = vocab.GloVe(name = '6B', dim = GLOVE_DIM)\n",
        "\n",
        "print('Loaded {} words in GloVe vocab'.format(len(glove.itos)))\n",
        "\n",
        "# Get Embedding for given word\n",
        "def get_word_embedding(word):\n",
        "    return glove.vectors[glove.stoi[word]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77f093ca",
      "metadata": {
        "id": "77f093ca"
      },
      "outputs": [],
      "source": [
        "start_tensor = torch.zeros(1, GLOVE_DIM, device = device) # Word Embedding Tensor for <start>\n",
        "unk_tensor = torch.rand(1, GLOVE_DIM, device = device) # Word Embedding Tensor for <unk>\n",
        "\n",
        "# Create Embedding Matrix for Vocab\n",
        "embeddings = []\n",
        "for word in word2idx:\n",
        "    if word in glove.stoi: # If word present in GloVe\n",
        "        embeddings.append(get_word_embedding(word)) \n",
        "    else:\n",
        "        if(word == '<start>'): # If word is <start>\n",
        "            embeddings.append(start_tensor) \n",
        "        else: # If word is <unk> or not present in GloVe\n",
        "            embeddings.append(unk_tensor)\n",
        "            \n",
        "temp_list = []\n",
        "for emb in embeddings:\n",
        "    temp_list.append(emb.detach().cpu().numpy().squeeze().tolist())\n",
        "# Tensor of Word Embeddings for each word in vocab\n",
        "embeddings_tensor = torch.tensor(temp_list, device = device)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rreSITqxWNAH",
      "metadata": {
        "id": "rreSITqxWNAH"
      },
      "source": [
        "#### Dataset Loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03117fb8",
      "metadata": {
        "id": "03117fb8"
      },
      "outputs": [],
      "source": [
        "# LangModel Class for DataLoader\n",
        "class DatasetLM(Dataset):\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self, data: list):\n",
        "        self.data = data\n",
        "        # Default Sequence Length\n",
        "        self.N = 30\n",
        "        self.words = self.load_words()\n",
        "        # Create List of tokens in the Corpus\n",
        "        self.token_list = []\n",
        "        for word in self.words:\n",
        "            if word in word2idx: \n",
        "                self.token_list.append(word2idx[word])\n",
        "            else:\n",
        "                self.token_list.append(1)\n",
        "    \n",
        "    # Length of Number of Sequences for a Dataset split\n",
        "    def __len__(self):\n",
        "        return len(self.token_list) - self.N\n",
        "    \n",
        "    def __getitem__(self, idx: int):\n",
        "        # Input Sequence Tensor\n",
        "        x = torch.tensor(self.token_list[idx : idx + self.N], device = device)\n",
        "        # Target Sequence Tensor\n",
        "        y = torch.tensor(self.token_list[idx + 1 : idx + self.N + 1], device = device)\n",
        "        return x, y\n",
        "\n",
        "    # List of Tokenized Words in the Corpus\n",
        "    def load_words(self):\n",
        "        tokenized_data = []\n",
        "        for sentence in self.data:\n",
        "            tokenized_data += ['<start>'] + sentence.split()\n",
        "        return tokenized_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "303e4604",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "303e4604",
        "outputId": "95a784e7-5f81-4488-c975-3ca00a19e152"
      },
      "outputs": [],
      "source": [
        "print(\"> Loading datasets ...\")\n",
        "\n",
        "# Train Dataset \n",
        "train_ds = DatasetLM(train_data)\n",
        "# Val Dataset Object\n",
        "val_ds = DatasetLM(val_data)\n",
        "# Test Dataset Object\n",
        "test_ds = DatasetLM(test_data)\n",
        "print(\"> Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uRBR-f--WKh-",
      "metadata": {
        "id": "uRBR-f--WKh-"
      },
      "source": [
        "#### Hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88f95442",
      "metadata": {
        "id": "88f95442"
      },
      "outputs": [],
      "source": [
        "# Model Hyper-Parameters\n",
        "BATCH_SIZE = 64\n",
        "EMBEDDING_DIM = GLOVE_DIM\n",
        "HIDDEN_DIM = 128\n",
        "OUTPUT_DIM = VOCAB_SIZE\n",
        "NUM_LAYERS = 2\n",
        "BIDIRECTION = False\n",
        "DROPOUT = 0.2\n",
        "LEARNING_RATE = 0.001\n",
        "MODEL_TYPE = 'lstm'\n",
        "N_EPOCHS = 10\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9be8a5ad",
      "metadata": {
        "id": "9be8a5ad"
      },
      "outputs": [],
      "source": [
        "# Train Data Loader\n",
        "train_loader = DataLoader(\n",
        "    train_ds, batch_size = BATCH_SIZE, shuffle = True)\n",
        "# Val Data Loader\n",
        "val_loader = DataLoader(\n",
        "    val_ds, batch_size = BATCH_SIZE, shuffle = True)\n",
        "# Test Data Loader\n",
        "test_loader = DataLoader(\n",
        "    test_ds, batch_size = 1, shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "I7PZGJOtWFdI",
      "metadata": {
        "id": "I7PZGJOtWFdI"
      },
      "source": [
        "#### Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e92e4dc",
      "metadata": {
        "id": "6e92e4dc"
      },
      "outputs": [],
      "source": [
        "# RNN / LSTM / GRU Model\n",
        "class LSTM(nn.Module):\n",
        "    \n",
        "    # Constructor\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, \n",
        "                 n_layers, bidirectional, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Initialize Pre-Trained GloVe Embeddings\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings_tensor)\n",
        "        # LSTM layer\n",
        "        self.lstm = nn.LSTM(\n",
        "            embedding_dim, hidden_dim,\n",
        "            num_layers = n_layers,\n",
        "            bidirectional = bidirectional,\n",
        "            dropout = dropout,\n",
        "            batch_first = True\n",
        "        )\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        # Dense layers for predicting \n",
        "        self.fc1 = nn.Linear(hidden_dim * num_directions, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    # Forward Pass of Model    \n",
        "    def forward(self, x):\n",
        "        # Embedding Layer\n",
        "        embedded = self.embedding(x)\n",
        "        # Dropout Layer before Seq Layer\n",
        "        embedded = self.dropout(embedded)\n",
        "         # LSTM Layer\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        # 1st Fully Connected Layer\n",
        "        out_fc1 = self.fc1(output)\n",
        "        # Dropout Layer before Output\n",
        "        out_dp = self.dropout(out_fc1)\n",
        "        # 2nd Fully Connected Layer\n",
        "        output = self.fc2(out_dp)\n",
        "        return output\n",
        "\n",
        "\n",
        "# GRU Model\n",
        "class GRU(nn.Module):        \n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, \n",
        "                n_layers, bidirectional, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Initialize Pre-Trained GloVe Embeddings\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings_tensor)\n",
        "        # GRU layer\n",
        "        self.gru = nn.GRU(\n",
        "            embedding_dim, hidden_dim,\n",
        "            num_layers = n_layers,\n",
        "            bidirectional = bidirectional,\n",
        "            dropout = dropout,\n",
        "            batch_first = True\n",
        "        )\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        # Dense layers for predicting \n",
        "        self.fc1 = nn.Linear(hidden_dim * num_directions, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    # Forward Pass of Model    \n",
        "    def forward(self, x):\n",
        "        # Embedding Layer\n",
        "        embedded = self.embedding(x)\n",
        "        # Dropout Layer before Seq Layer\n",
        "        embedded = self.dropout(embedded)\n",
        "        # GRU Layer\n",
        "        output, hidden = self.gru(embedded)\n",
        "        # 1st Fully Connected Layer\n",
        "        out_fc1 = self.fc1(output)\n",
        "        # Dropout Layer before Output\n",
        "        out_dp = self.dropout(out_fc1)\n",
        "        # 2nd Fully Connected Layer\n",
        "        output = self.fc2(out_dp)\n",
        "        return output\n",
        "\n",
        "\n",
        "# RNN\n",
        "class RNN(nn.Module):\n",
        "    def __init__(self, embedding_dim, hidden_dim, output_dim, \n",
        "                n_layers, bidirectional, dropout):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Initialize Pre-Trained GloVe Embeddings\n",
        "        self.embedding = nn.Embedding.from_pretrained(embeddings_tensor)\n",
        "        # RNN layer\n",
        "        self.rnn = nn.RNN(\n",
        "            embedding_dim, hidden_dim,\n",
        "            num_layers = n_layers,\n",
        "            bidirectional = bidirectional,\n",
        "            dropout = dropout,\n",
        "            batch_first = True\n",
        "        )\n",
        "        num_directions = 2 if bidirectional else 1\n",
        "        # Dense layers for predicting \n",
        "        self.fc1 = nn.Linear(hidden_dim * num_directions, hidden_dim)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
        "        # dropout\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        \n",
        "    # Forward Pass of Model    \n",
        "    def forward(self, x):\n",
        "        # Embedding Layer\n",
        "        embedded = self.embedding(x)\n",
        "        # Dropout Layer before Seq Layer\n",
        "        embedded = self.dropout(embedded)\n",
        "        # RNN Layer\n",
        "        output, hidden = self.rnn(embedded)\n",
        "        # 1st Fully Connected Layer\n",
        "        out_fc1 = self.fc1(output)\n",
        "        # Dropout Layer before Output\n",
        "        out_dp = self.dropout(out_fc1)\n",
        "        # 2nd Fully Connected Layer\n",
        "        output = self.fc2(out_dp)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KDI3Plq694RU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDI3Plq694RU",
        "outputId": "27cdb9e3-feb3-49df-cf93-1063d32a669e"
      },
      "outputs": [],
      "source": [
        "\n",
        "def get_model(model) -> nn.Module:\n",
        "\n",
        "    if model == 'rnn':\n",
        "        return RNN(\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            NUM_LAYERS, \n",
        "            BIDIRECTION,\n",
        "            DROPOUT).to(device)\n",
        "    \n",
        "    elif model == 'gru':\n",
        "        return GRU(\n",
        "            EMBEDDING_DIM,\n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM,\n",
        "            NUM_LAYERS, \n",
        "            BIDIRECTION, \n",
        "            DROPOUT).to(device)\n",
        "\n",
        "    elif model == 'lstm':\n",
        "        return LSTM(\n",
        "            EMBEDDING_DIM, \n",
        "            HIDDEN_DIM, \n",
        "            OUTPUT_DIM, \n",
        "            NUM_LAYERS, \n",
        "            BIDIRECTION, \n",
        "            DROPOUT).to(device)\n",
        "\n",
        "model = get_model(\n",
        "    model=MODEL_TYPE\n",
        ")\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nnoIoVyZV_oJ",
      "metadata": {
        "id": "nnoIoVyZV_oJ"
      },
      "source": [
        "#### Training and Evaluation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f887dd4",
      "metadata": {
        "id": "1f887dd4"
      },
      "outputs": [],
      "source": [
        "# Model Train Function\n",
        "def train(loader, model, optimizer, loss_function):\n",
        "    model.train()\n",
        "    losses = [] \n",
        "    for batch in tqdm(loader, desc='Training'):\n",
        "        x, y = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        y_pred = model(x)\n",
        "        \n",
        "        # Convert y_pred -> 2D Tensor and y-> 1D Tensor\n",
        "        y_pred = y_pred.view(-1, y_pred.shape[-1]) \n",
        "        y = torch.flatten(y) \n",
        "        \n",
        "        # Loss\n",
        "        loss = loss_function(y_pred, y)\n",
        "        losses.append(loss.item())\n",
        "        \n",
        "        # Calculate gradients and update weights\n",
        "        loss.backward()  \n",
        "        optimizer.step()\n",
        "    return round((sum(losses) / len(losses)), 4) # Return Average Loss\n",
        "\n",
        "\n",
        "# Model Evaluate Function\n",
        "def evaluate(loader, model, loss_function):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    for batch in tqdm(loader, desc='Evaluate'):\n",
        "        x, y = batch \n",
        "        y_pred = model(x)\n",
        "              \n",
        "        # Convert y_pred -> 2D Tensor and y-> 1D Tensor\n",
        "        y_pred = y_pred.view(-1, y_pred.shape[-1])\n",
        "        y = torch.flatten(y)\n",
        "        \n",
        "        # Loss\n",
        "        loss = loss_function(y_pred, y)\n",
        "        losses.append(loss.item())\n",
        "    \n",
        "    return round((sum(losses) / len(losses)), 4) # Return Average Loss"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g9aPdM5aV7dI",
      "metadata": {
        "id": "g9aPdM5aV7dI"
      },
      "source": [
        "#### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f300ceb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f300ceb",
        "outputId": "f5aab2c0-1c94-4446-c807-538bc4c0f0b8"
      },
      "outputs": [],
      "source": [
        "# Model Training on Train dataset and Evaluation on Validation dataset\n",
        "\n",
        "# Optimizer\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "# Loss Function -> Cross-Entropy Loss\n",
        "loss_func = nn.CrossEntropyLoss().to(device)\n",
        "\n",
        "train_losses, val_losses = [], []\n",
        "train_perplexities, val_perplexities = [], []\n",
        "\n",
        "\n",
        "# Path to Save Best Model\n",
        "PATH = f'output/best-model.pt'\n",
        "\n",
        "for epoch in range(N_EPOCHS):\n",
        "    print(\"EPOCH: \", epoch+1)\n",
        "\n",
        "    # Avg Training Loss\n",
        "    train_loss = train(\n",
        "        loader=train_loader,\n",
        "        model=model,\n",
        "        optimizer=optimizer,\n",
        "        loss_function=loss_func\n",
        "    )\n",
        "    train_losses.append(train_loss)\n",
        "    \n",
        "    # Train Perplexity\n",
        "    train_ppl = torch.exp(\n",
        "        torch.tensor(train_loss, device = device))\n",
        "    train_perplexities.append(\n",
        "        train_ppl.detach().cpu().numpy())\n",
        "    \n",
        "    # Avg Val Loss\n",
        "    val_loss = evaluate(\n",
        "        loader=val_loader,\n",
        "        model=model,\n",
        "        loss_function=loss_func\n",
        "    )\n",
        "    val_losses.append(val_loss)\n",
        "    # Val Perplexity\n",
        "    val_ppl = torch.exp(\n",
        "        torch.tensor(val_loss, device = device))\n",
        "    val_perplexities.append(\n",
        "        val_ppl.detach().cpu().numpy())\n",
        "    \n",
        "    print(f\"Train Loss: {train_loss:.4f} | Train Perplexity: {train_ppl:.4f} | Val Loss: {val_loss:.4f} | Val Perplexity: {val_ppl:.4f} \\n\")\n",
        "    \n",
        "    # Save model\n",
        "    torch.save(model.state_dict(), PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09fb3245",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "09fb3245",
        "outputId": "92db7698-3e4a-44c9-f766-72239fa69141"
      },
      "outputs": [],
      "source": [
        "# Line Plot Comparison\n",
        "epochs = np.arange(N_EPOCHS) + 1\n",
        "\n",
        "def draw_plot(line_A_vals, line_B_vals, line_A_label, line_B_label, \n",
        "              xlabel, ylabel, title, colors):\n",
        "    plt.style.use('ggplot')\n",
        "    plt.plot(\n",
        "        epochs, line_A_vals, label=line_A_label, color=colors[0], linewidth='3')\n",
        "    plt.plot(\n",
        "        epochs, line_B_vals, label=line_B_label, color=colors[1], linewidth='3')\n",
        "    plt.xlabel(xlabel)\n",
        "    plt.xticks(epochs)\n",
        "    plt.ylabel(ylabel)\n",
        "    plt.title(title, color = 'black')\n",
        "    plt.legend(shadow = True)\n",
        "    \n",
        "# Training vs Validation Loss Plot\n",
        "draw_plot(train_losses, val_losses, \n",
        "          'Training Loss', \n",
        "          'Validation Loss', \n",
        "          'Epoch', \n",
        "          'Loss', \n",
        "          'Training Loss vs Validation Loss', \n",
        "          ['green', 'red'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d32dcf1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "5d32dcf1",
        "outputId": "9dd8f88c-5cf2-4f2c-e8d9-d0027f5db8b1"
      },
      "outputs": [],
      "source": [
        "# Training vs Validation Perplexity Plot\n",
        "draw_plot(train_perplexities, \n",
        "          val_perplexities, \n",
        "          'Training Perplexity', \n",
        "          'Validation Perplexity', \n",
        "          'Epoch', \n",
        "          'Perplexity', \n",
        "          'Training Perplexity vs Validation Perplexity', \n",
        "          ['green', 'red'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb1fe57c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb1fe57c",
        "outputId": "4192de35-0f39-40d5-8677-3a83178a9565"
      },
      "outputs": [],
      "source": [
        "# Load the saved model\n",
        "saved_model = get_model(model=MODEL_TYPE)\n",
        "\n",
        "saved_model.load_state_dict(torch.load(PATH))\n",
        "saved_model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "befc2dc8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "befc2dc8",
        "outputId": "1fd8cd00-ad3a-4558-b250-cffb22000035"
      },
      "outputs": [],
      "source": [
        "# Model Test Function\n",
        "def test(loader, model, loss_function):\n",
        "    # Set model to eval mode\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    for batch in tqdm(loader, desc = 'Test: '):\n",
        "        x, y = batch\n",
        "        with torch.no_grad():\n",
        "            \n",
        "            y_pred = model.forward(x)\n",
        "            # Convert (y_pred -> 2D Tensor) and (y -> 1D Tensor)\n",
        "            y_pred = y_pred.view(-1, y_pred.shape[-1]) \n",
        "            y = torch.flatten(y)\n",
        "            \n",
        "            # Loss\n",
        "            loss = loss_function(y_pred, y)\n",
        "            losses.append(loss.item())\n",
        "    \n",
        "    return round((sum(losses) / len(losses)), 4) # Return Average Loss\n",
        "\n",
        "# Avg Test Loss\n",
        "test_loss = test(\n",
        "    loader=test_loader,\n",
        "    model=saved_model,\n",
        "    loss_function=loss_func\n",
        ")\n",
        "# Test Perplexity\n",
        "test_perplexity = torch.exp(\n",
        "    torch.tensor(test_loss, device = device))\n",
        "\n",
        "print()\n",
        "print(f\"Test Loss: {test_loss} | Test Perplexity: {test_perplexity}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "28871ceb77ca11509dace590eaf42f33d015750868e9dcad7570bbdfa2dda0bf"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "212c13238a284306a460283098722aa4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3d2501ddf98f44e9bbe04a543850e632": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4435356fa71a43a18722c9690ba65baf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cf24b683f9b42ceb013484313a1adf9",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_212c13238a284306a460283098722aa4",
            "value": 3
          }
        },
        "5f3b35b26023438196043a8b10ad45c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95e8fad990ad418c865fefcf4ec0754a",
            "placeholder": "​",
            "style": "IPY_MODEL_7051e36a3fd4470bb64a86c5f8ee4c3c",
            "value": "100%"
          }
        },
        "7051e36a3fd4470bb64a86c5f8ee4c3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "71e4d85613ef40c68f43f2fd532b9174": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cf24b683f9b42ceb013484313a1adf9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95e8fad990ad418c865fefcf4ec0754a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a13b454c3a4c49c8bacdf512b57d9d02": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b2d86fcf25244ca89735ec259fa0815f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5f3b35b26023438196043a8b10ad45c4",
              "IPY_MODEL_4435356fa71a43a18722c9690ba65baf",
              "IPY_MODEL_f3b078b908ed4f66bad274c034e1c0e2"
            ],
            "layout": "IPY_MODEL_71e4d85613ef40c68f43f2fd532b9174"
          }
        },
        "f3b078b908ed4f66bad274c034e1c0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3d2501ddf98f44e9bbe04a543850e632",
            "placeholder": "​",
            "style": "IPY_MODEL_a13b454c3a4c49c8bacdf512b57d9d02",
            "value": " 3/3 [00:00&lt;00:00, 83.86it/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
